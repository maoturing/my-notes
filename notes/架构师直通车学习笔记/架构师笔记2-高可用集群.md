# 0. 单体架构与集群

单体架构面临的挑战:
1. 单节点宕机导致所有服务不可用
2. 耦合度高, 代码可读性, 可维护性, 可扩展性都受到了限制. 不利于迭代,  上线时测试人员需要对所有耦合功能进行测试
3. 单节点并发能力有限


使用集群的优势:
1. 提高系统性能
2. 提高系统可用性
3. 可扩展性高
   

使用集群的注意点:
1. 用户会话需要修改为分布式会话
2. 定时任务

# 1. Nginx 入门

Nginx 是一个高性能的 HTTP 和反向代理 Web 服务器. 主要功能有反向代理，通过配置文件可以实现集群和负载均衡，静态资源虚拟化

## 1.1 反向代理

**正向代理：** 客户端请求目标服务器，请求会先经过中间的代理服务器，然后转发请求到目标服务器，代理服务器获得内容后最后响应给客户端；例如翻墙通过代理服务器来访问目标网站，获得内容后由代理返回。

**反向代理：** 用户请求目标服务器，由**代理服务器**决定访问哪个 ip

大型网站都是用了 Nginx，我们访问淘宝，而淘宝有许多个服务器，每次访问到的目标服务器都是不同的 ip，这个 ip 由**反向代理服务器**决定。即用户的请求发给 Nginx，然后由 Nginx 进行负载均衡，选择一个目标服务器进行访问并返回。
```cmd
> ping www.taobao.com 
来自 119.84.72.77 的回复: 字节=32 时间=21ms TTL=55

# 一段时间后再次访问taobao.com, 发现请求的是不同IP
> ping www.taobao.com 
来自 118.112.19.100 的回复: 字节=32 时间=17ms TTL=46
```
## 1.2 安装运行 Nginx

在[官网](http://nginx.org/en/download.html)下载 Niginx，安装过程见文档1-5，结合[文章](https://blog.csdn.net/chenxiaochan/article/details/63688346)进行安装，安装命令会指定安装目录，进入 Nginx 安装目录：

启动：`./sbin/nginx`

停止：`./sbin/nginx -s stop`

重新加载：`./sbin/nginx -s reload`

访问: 关闭防火墙，浏览器中输入虚拟机IP即可



## 1.3 Nginx 配置文件

打开 nginx 的配置文件 `vim ./conf/nginx.conf `/，配置文件修改后需要重新加载才能生效

```nginx
server {
    listen       89;		# 监听的端口
    server_name  localhost;		# 绑定域名

    location / {
        root   html;		# 相对路径, 即nginx下的html目录
        index  imooc.html index.htm;  # 配置首页,
    }
}
```



## 1.4 Nginx 的进程模型

- master进程：主进程
- worker进程：工作进程，默认只有 1 个

```bash
# 查看nginx进程, 发现有一个master和worker
[root@bigdata01 nginx]# ps -ef | grep nginx
root       5616      1  0 09:45 ?        00:00:00 nginx: master process ./sbin/nginx
nobody     5617   5616  0 09:45 ?        00:00:00 nginx: worker process
root       5673   1236  0 10:01 pts/0    00:00:00 grep --color=auto nginx
```

可以在 nginx.conf 中将工作线程 worker 的数量修改为 2 

```nginx
#user  nobody;
worker_processes  2;
```



master 用来管理 worker 进程，master 会接收外面的信号，将信号传递给 worker，master 会监控 worker，当 worker 退出了，master 会启动新的 worker。

常见的 4 种信号，-s 表示信号 signal

`./nginx -s stop`

`./nginx -s quit`

`./nginx -s reload`

`./nginx -t`  检测配置文件是否合法，修改配置文件后，可以先检测，再加载



## 1.5 Worker 抢占机制（重点）

Nginx 是一个性能非常好的服务器，处理的并发数可以达到几百万。

如下图所示，nginx 配置了 3 个 worker 进程。当客户端发送请求给 master，3 个 worker 进程会去抢这个请求，具体表现为竞争一个互斥锁`accept_mutex`，抢到锁的 worker 进程来处理该 client 的请求。

![image-20211110101616117](https://raw.githubusercontent.com/maoturing/PictureBed/master/picGo/image-20211110101616117.png)



### 1. 传统服务器事件处理

传统服务器处理客户端请求，当 client1 的请求阻塞后，worker1 会一直等待；后面的 client2 的请求，master 会创建新的 worker2 来进行处理，当 client2 的请求也阻塞后，worker2 会一直等待，后面的 client3 的请求，master 会创建新的 worker3 来进行处理。于是当并发量特别大时并且出现多个阻塞时，master 就会创建大量的 worker 进程，服务器资源开销会非常大。

![image-20211110103653491](https://raw.githubusercontent.com/maoturing/PictureBed/master/picGo/image-20211110103653491.png)



### 2. Nginx 事件处理

Nginx 处理客户端请求，当 client1 的请求阻塞后，worker1不会傻傻等待，而是会处理 client2 的请求，同样的，client2 的请求阻塞后，worker1 会去处理 client3 的请求。Nginx 使用了 linux 的 epoll 模型，一个 worker 可以并发处理 6-8w 个请求，所以 Nginx 只需要很少的 worker 进程就可以处理几百万的并发请求。

linux 的 epoll 模型是编写高性能服务端的重要技术，是异步非阻塞的，netty 也会使用。内核会监听多个 I/O 流，当某些 I/O 流变为就绪状态，内核会把这些 I/O 流添加到就绪队列中，然后通知进程处理就绪队列中的 I/O 流。具体参考[文章](https://mp.weixin.qq.com/s/pMT40ROU7fhz_x_RgR7xOQ)。

![image-20211110102845454](https://raw.githubusercontent.com/maoturing/PictureBed/master/picGo/image-20211110102845454.png)



### 3. 同步与阻塞

关于同步与异步，阻塞与非阻塞，见文档 1-10。简单来说，

1. 同步就是客户端会一直等待结果，
2. 异步就是客户端不会等待结果，服务端处理完会通知客户端
3. 阻塞就是服务端会处理完一个任务后，再处理下一个任务
4. 非阻塞就是服务端处理其他任务，过一会再处理原先的任务，不存在某个任务没处理完堵着，后面任务也没法处理



### 4. 设置 worker 连接数

Nginx 的事件处理可以在 `nginx.conf` 中进行配置，worker_connections 用来设置每个 worker 允许连接客户端的最大连接数

```nginx
events {
    # 默认使用epoll, 可省略
    use epoll;
    # 每个worker进程允许的客户端最大连接数
    worker_connections  1024;
}
```



> 问题1：发送一个请求，会占用 worker 的几个连接数？

答：2个或4个，请求静态资源，client 请求 worker，worker 返回资源，共占用两个连接。请求后端，worker 还有与 tomcat 建立来回两个连接，因此是 4 个

> 问题2：nginx 有1个master，4个worker，每个worker支持的最大连接数是1024，那么nginx 支持的最大并发数是多少？

静态资源访问的最大并发数：woker_connection * worker_processes / 2 = 4 * 1024 / 2 = 2048

http反向代理：woker_connection * worker_processes / 4 = 4 * 1024 / 4 = 1024





## 1.6 配置文件结构

配置文件`nginx.conf`的结构如下所示

![image-20211110112228143](https://raw.githubusercontent.com/maoturing/PictureBed/master/picGo/image-20211110112228143.png)

配置文件的详细属性讲解见文档 1-11



1. 设置创建 worker 进程的用户，指 linux 中的用户，会涉及到 nginx 操作目录或文件的一些权限，默认为 nobody。这里我们手动修改为 root

```nginx
user  root;
```

​	修改后重新加载配置文件，可以看到 worker 线程的用户从 nobody 变为了 root。

```shell
[root@bigdata01 nginx]# ./sbin/nginx -s reload
[root@bigdata01 nginx]# ps -ef | grep nginx
root       5616      1  0 09:45 ?        00:00:00 nginx: master process ./sbin/nginx
root       5731   5616  0 11:56 ?        00:00:00 nginx: worker process
root       5732   5616  0 11:56 ?        00:00:00 nginx: worker process
root       5734   1236  0 11:56 pts/0    00:00:00 grep --color=auto nginx
```

2. worker进程工作数设置，一般来说CPU有几个，就设置几个，或者设置为N-1也行

```nginx
worker_processes  2;
```

3. 设置 nginx 日志的文件路径，并且设置打印的日志等级。日志等级有 debug | info | notice | warn | error | crit | alert | emerg ，错误级别从左到右越来越大。

```nginx
#error_log  logs/error.log;
#error_log  logs/error.log  notice;
#error_log  logs/error.log  info;
```

不过我们在安装 nginx makefile 阶段都设置了日志路径`--error-log-path=/var/log/nginx/error.log`，所以这里不需要再设置

4. 保存 nginx 进程 pid 的文件名，这个文件内容只保存了 nginx 的进程号。

```nginx
#pid        logs/nginx.pid;
```

不过我们在安装 nginx makefile 阶段都设置了保存进程号的文件`–pid-path=/var/run/nginx/nginx.pid`，所以这里不需要再设置

5. `events`设置事件处理模式，epoll 只在 linux 中有效。`worker_connections`设置每个 worker 进程允许的客户端最大连接数

```nginx
events {
    # 默认使用epoll
    use epoll;
    # 每个worker 进程允许的客户端最大连接数
    worker_connections  10240;
}
```

6. http 是指令块，针对http网络传输的一些指令配置

```nginx
http{
}
```

7. `include`引入外部配置，提高可读性，避免单个配置文件过大。这里引入的是 `nginx/conf/mine.types`，配置了 http 请求的数据类型，包括 css，js，html，jpg 等等

```nginx
http{
	# 引入外部配置
	include       mime.types;
    # http请求的默认数据类型
    default_type  application/octet-stream;
```

8. `log_format`设置客户端 http 访问日志格式，main 为定义的格式名称，这样下面的日志路径`access_log`就可以使用这个变量了。不过我们在安装 nginx makefile 阶段都设置了访问日志`--http-log-path=/var/log/nginx/access.log`，所以这里不需要再设置

    ```nginx
    http {
        # http访问日志格式
        #log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
        #                  '$status $body_bytes_sent "$http_referer" '
        #                  '"$http_user_agent" "$http_x_forwarded_for"';
    		
      	# http访问日志路径, 这里指的是客户端访问nginx后会进行记录,与错误日志不同
        #access_log  logs/access.log  main;
    ```

    查看`access.log`日志内容如下，可以看到，日志记录了 http 请求客户端的 ip，请求方式 GET，请求结果 404，请求的资源 /favicon.ico，请求的浏览器等数据

    ```
    192.168.252.1 - - [10/Nov/2021:09:50:06 +0800] "GET / HTTP/1.1" 200 642 "-" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/95.0.4638.69 Safari/537.36 Edg/95.0.1020.44"
    192.168.252.1 - - [10/Nov/2021:09:50:06 +0800] "GET /favicon.ico HTTP/1.1" 404 571 "http://192.168.252.100:88/" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/95.0.4638.69 Safari/537.36 Edg/95.0.1020.44"日志格式
    ```

    日志格式参数如下所示：

![image-20211110122853273](https://raw.githubusercontent.com/maoturing/PictureBed/master/picGo/image-20211110122853273.png)

9. `sendfile`使用高效文件传输，提升传输性能。启用后才能使用`tcp_nopush`，是指当数据表累积一定大小后才发送，提高了效率。

    ```nginx
    http{
      
        sendfile        on;
        #tcp_nopush     on;
    ```

10.  `keepalive_timeout` 设置客户端与服务端请求的超时时间，单位是秒，保证客户端多次请求的时候不会重复建立新的连接，节约资源损耗。

    ```nginx
        # 保持连接的时长，但是是秒
    	keepalive_timeout  65;
    ```

    客户端在请求服务端结束后，要进行连接的断开，如果客户端发送了多个请求，那么每个请求都要连接断开，http 有 keepalive 模式，告诉 web 服务器处理完一个请求后，保持 tcp 连接，如果接收到客户端其他 http 请求后，就可以利用这个还没关闭 tcp 连接，而不需要再次创建新的 tcp 连接。

    很多浏览器也有默认的 keepalive 设置，一般为 60 秒。

11. `gzip` 启用压缩，html/js/css 在压缩后传输会更快。因为是压缩后传输，所以占用带宽会降低，传输速度会变快，但是压缩操作也会占用服务端 CPU 的性能。

    ```nginx
    	#gzip  on;
    ```

12. `server`可以在配置多个虚拟主机

    - listen 监听端口

    - server_name 可以配置ip和域名

    - location 请求路由映射，匹配拦截

    - root 资源位置

    - index 首页html页面，

        

    这里我们添加了一个虚拟主机，监听端口为 89，访问`http://localhost:89/`将默认展示的首页`imooc.html`

```nginx
server {
  listen       88;
  server_name  localhost;
	
  location / {
    root   html;
    index  index.html index.htm;
  }
  error_page  500 502 503 504  /50x.html;
  location = /50x.html {
    root  html;
  }
}

# 自己配置的虚拟主机
server {
  listen       89;
  server_name  localhost;

  # 访问 http://localhost:89/ 时默认展示的页面
  location / {
    root   html;
    index  imooc.html index.htm;
  }
}
```



> 错误：找不到 nginx.pid 文件
>
> nginx: [error] open() “/var/run/nginx/nginx.pid” failed (2: No such file or directory)

1. 检查目录是否存在，如果不存在则创建

```bash
cd /var/run/nginx/
mkdir /var/run/nginx/
./nginx -s reload
```

> 错误：PID 无效
>
> nginx: [error] invalid PID number “” in “/var/run/nginx/nginx.pid”

1. 指定配置文件，重新加载配置文件即可

```bash
./nginx -c /usr/local/nginx/conf/nginx.conf
./nginx -s reload
```



## 1.7 Nginx 常见命令解析

- `./nginx -s quit`  等已连接的用户通信结束后，停止nginx服务
- `./nginx -s stop`  立刻停止nginx服务，所有用户的连接都会被关闭，很少使用。

前者相当于饭店晚上要打烊了，不再接待新客户了，等正在吃饭的客户结束了，再关闭饭店。后者相当于立刻赶走正在吃饭的客户并关门。

- `./nginx -t`  检测（-test）配置文件`nginx.conf`的语法格式
- `./nginx -v`  查看 nginx 的版本号，
- `./nginx -V`  显示安装 nginx 时配置的相关参数，包括 pid 文件路径，错误日志路径，http访问日志路径等。**（重点）**
- `./nginx -c`  指定配置文件，在实际生产中，可能会有多个配置文件，可以使用该命令进行切换
- `./nginx -h`  帮助命令

```bash
[root@bigdata01 nginx]# ./sbin/nginx -h
nginx version: nginx/1.15.1
Usage: nginx [-?hvVtTq] [-s signal] [-c filename] [-p prefix] [-g directives]

Options:
  -?,-h         : this help
  -v            : show version and exit
  -V            : show version and configure options then exit
  -t            : test configuration and exit
  -T            : test configuration, dump it and exit
  -q            : suppress non-error messages during configuration testing
  -s signal     : send signal to a master process: stop, quit, reopen, reload
  -p prefix     : set prefix path (default: /usr/local/nginx/)
  -c filename   : set configuration file (default: conf/nginx.conf)
  -g directives : set global directives out of configuration file
```



## 1.8 Nginx 日志切割（不重要）



### 1. 手动切割日志

现有的日志都会存在`access.log`文件中，但是随着时间的推移，这个文件的内容会越来越多，体积会越来越大，不便于运维人员查看，所以我们可以通过把 文件切割为多份不同的小文件作为日志，切割规则可以以 天 为单位，如果每天有几百G或者几个T的日志的话，则可以按需以 每半天 或者 每小时 对日志切割。具体步骤如下：

1. 创建一个 shell 可执行文件`cut_my_log.sh`

```shell
#!/bin/bash
LOG_PATH="/var/log/nginx/"
RECORD_TIME=$(date -d "yesterday" +%Y-%m-%d+%H:%M)
PID=/var/run/nginx/nginx.pid
mv ${LOG_PATH}/access.log ${LOG_PATH}/access.${RECORD_TIME}.log
mv ${LOG_PATH}/error.log ${LOG_PATH}/error.${RECORD_TIME}.log
#向Nginx主进程发送信号，用于重新打开日志文件
kill -USR1 `cat $PID`
```

2. 为 cut_my_log.sh 添加可执行的权限：

```shell
chmod +x cut_my_log.sh
```

3. 执行 shell 脚本，测试日志切割后的结果

```shell
# 切割日志
$ ./cut_my_log.sh
$ cd /var/log/nginx/
$ ll
-rw-r--r--. 1 root root 12875 Nov 10 14:15 access.2021-11-09+14:48.log
# 日志文件为空，这样就可以测试打印日志了
# 当然开发环境我们习惯将原来日志直接删除，生产环境上过大的日志不方便查看，切割后进行测试
-rw-r--r--. 1 root root     0 Nov 10 14:48 access.log
-rw-r--r--. 1 root root  8225 Nov 10 14:15 error.2021-11-09+14:48.log
-rw-r--r--. 1 root root     0 Nov 10 14:48 error.log
```

可以看到，当前时间以前的日志被切割到`access.2021-11-09+14:48.log`中，这样我们测试 nginx 的日志就会打印到`access.log`，方便我们查看日志。



### 2.定时动切割日志

1. 安装定时任务

    ```shell
    yum install crontabs
    ```

2. `crontab -e` 编辑并且添加一行新的任务

    ```shell
    # 每分钟执行一次shell脚本
    */1 * * * * /usr/local/nginx/sbin/cut_my_log.sh
    ```

3. 重启定时任务

    ```shell
    service crond restart
    ```
    
4. 查看定时切割后的日志，可以看到每分钟都生成了一个日志文件

```
[root@bigdata01 nginx]# ll
total 32
-rw-r--r--. 1 root root   208 Nov 10 14:48 access.2021-11-09+15:05.log
-rw-r--r--. 1 root root     0 Nov 10 15:05 access.2021-11-09+15:06.log
-rw-r--r--. 1 root root     0 Nov 10 15:06 access.2021-11-09+15:07.log
-rw-r--r--. 1 root root     0 Nov 10 15:07 access.log
-rw-r--r--. 1 root root     0 Nov 10 14:48 error.2021-11-09+15:05.log
-rw-r--r--. 1 root root     0 Nov 10 15:05 error.2021-11-09+15:06.log
-rw-r--r--. 1 root root     0 Nov 10 15:06 error.2021-11-09+15:07.log
-rw-r--r--. 1 root root     0 Nov 10 15:07 error.log
```



 附：常用定时任务命令： 

```shell
service crond start   //启动服务 
service crond stop    //关闭服务 
service crond restart //重启服务 
service crond reload  //重新载入配置 
crontab -e            // 编辑任务 
crontab -l 	          // 查看任务列表
```

**定时任务表达式：** 

Cron表达式是，分为5或6个域，每个域代表一个含义，如下所示： 

|              | 分   | 时   | 日   | 月   | 星期几 | 年（可选）       |
| ------------ | ---- | ---- | ---- | ---- | ------ | ---------------- |
| **取值范围** | 0-59 | 0-23 | 1-31 | 1-12 | 1-7    | 2019/2020/2021/… |

**常用表达式：**

-  每分钟执行：

  ```
  */1 * * * *
  ```

- 每日凌晨（每天晚上23:59）执行： 

  ```
  59 23 * * * 
  ```

- 每日凌晨1点执行：

  ```
   0 1 * * *
  ```

  

## 1.9 发布静态资源

1. 修改 Nginx 配置文件，这里修改被引入的 imooc.conf 即可

```nginx
server {
    listen       90;
    server_name  localhost;

    # 前端的静态资源
    location / {
        root   /home/foodie-shop;
        index  index.html;
    }

  	# 静态资源
    location /imooc {
        root   /home;
    }
  
    # 静态资源,与上面等价,优点是用户无法知道具体资源的目录
    location /static {
        alias   /home/imooc;
    }
}
```

2. 加载配置文件

```bash
./nginx -t
./nginx -s reload
```

3. 访问静态资源，`http://192.168.252.100:90/`会返回`/home/foodie-shop`目录下的`index.html`文件。
4. 访问静态资源，`http://192.168.252.100:90/imooc/img/a.jpg` 会返回`/home/imooc`目录下的`a.jpg`文件，这里不要搞混了。

5. 访问别名处理过的静态资源，`http://192.168.252.100:90/static/img/ow.mp4`会返回`/home/imooc`目录下的`ow.mp4`文件
6. 通过以上步骤不难发现，location 等于 root，当 url 与 location 匹配后，将会从 root 作为根路径开始查找文件

关于 location 的匹配规则见文档 1-26



## 1.10 压缩数据

1. 在`nginx.conf`中打开 gzip 压缩，并配置相关属性

```nginx
# 开启gzip亚索功能, 能提高传输效率节约带宽
gzip on;
# 限制最小压缩, 小于1字节文件不会压缩
gzip_min_length  1;
# 压缩比, 1-9, 数字越大,压缩越多, 但cpu资源占用更多
gzip_comp_level  3;
# 设置需要压缩的文件类型
gzip_types text/plain application/javascript application/x-javascript text/css application/xml text/javascript application/x-httpd-php image/jpeg image/gif image/png application/json;
```

2. 加载配置文件

```shell
./nginx -t
./nginx -s reload
```

3. 重新访问页面，329kB的 amazeui.css 被压缩为 60kB，效果非常显著。



## 1.11 DNS 解析域名

当用户访问慕课网时，会先去 DNS 解析域名，获得 Nginx 的 ip 地址，然后访问 Nginx，Nginx 会将请求分发给内网的 Tomcat。Nginx 相当于小区大门，谁都可以过来访问，Tomcat 像小区里的房子，外面的人没法直接访问，必须通过大门的安检，即 Nginx 也有一个网关的作用，能提供一些防范措施。

![image-20211110173619347](https://raw.githubusercontent.com/maoturing/PictureBed/master/picGo/image-20211110173619347.png)





# 2. Nginx 进阶与实战



## 2.1 Nginx 跨域

### 1. 什么是跨域？

为了出于安全的考虑，W3C 规定浏览器禁止违反**同源策略**的访问，**域名、协议、端口**均相同才可以被称为同源。

对于需要跨域的访问，需要遵守 CORS (Cross=origin Resource Sharing) 跨域资源共享规则。是浏览器对JavaScript实施的安全限制，如果是自己写个没有同源策略的浏览器，完全就不用考虑跨域问题了。

![image-20211213083555833](https://gitee.com/tracccer/picture-bed/raw/master/img/image-20211213083555833.png)

上图中，浏览器前端代码向同域名发起 js 请求正常获取响应，而向不同域名的服务器发起 js 请求会发生错误如下所示。

![image-20211213084513021](https://gitee.com/tracccer/picture-bed/raw/master/img/image-20211213084513021.png)

上图显示来这个`http://localhost:8088`登录请求，是来自来自源 Origin 域名`http://localhost:8088`，违反了 CORS 规则，因为响应头中没有`Access-Control-Allow-Origin`属性。



### 2. 为什么要限制跨域 ？

[浅谈CSRF攻击方式 - hyddd - 博客园 (cnblogs.com)](https://www.cnblogs.com/hyddd/archive/2009/04/09/1432744.html)

[为什么浏览器要限制跨域访问? - 知乎 (zhihu.com)](https://www.zhihu.com/question/26379635)

简单来说，你的浏览器保存了你的支付宝和QQ邮箱的 Cookie，你如果访问了一个网站A，那么这个A网站可以跨域向支付宝，QQ邮箱发送请求，利用 Cookie 冒充你的身份进行转账和发邮件

![img](https://gitee.com/tracccer/picture-bed/raw/master/img/2009040916453171.jpg)



### 3. 跨域访问原理

1. 当使用 XMLHttpRequest 发送`PUT`请求时，如果浏览器发现是跨域请求，就会自动发出一个预检请求，会自动加上一个请求头 `Origin: http://localhost:8080`，要求服务器确认是否允许该域的请求，
2. 后端在接受到请求后，首先会使用过滤器`CorsFilter`判断请求是否违反同源策略，若请求来源在我们设置的可信域，则会在 Response Headers 中加入一个属性`Access-Control-Allow-Origin: http://localhost:8080`；
3. 浏览器判断响应中的 Access-Control-Allow-Origin 值是否和当前的地址相同，匹配成功则说明服务端认为当前域是可信的，发送真实的请求，则否则报错 403

这里说的并不详细，详细参考下面几篇文章

[跨域资源共享 CORS 详解 - 阮一峰](http://www.ruanyifeng.com/blog/2016/04/cors.html)

[CORS跨域原理解析 - 掘金](https://juejin.cn/post/6844903859068862472)

[跨域请求产生错误的原因及处理方法](https://cloud.tencent.com/developer/article/1745763)





### 4. 跨域解决办法

- SpringBoot 解决跨域

  原理就是在接收到跨域请求时，过滤器`CorsFilter`会判断请求源`Origin`是否在我们设置的可信域内，若在可信域内，则在响应中添加`Access-Control-Allow-Origin`并返回。具体操作由`org.springframework.web.filter.CorsFilter#doFilterInternal`完成。

```java
@Bean
CorsFilter corsFilter() {
    // 1.添加cors配置信息
    CorsConfiguration cors = new CorsConfiguration();
    // 添加允许的请求端, 若设置为 * 表示允许任何域的跨域访问
    cors.addAllowedOrigin("http://localhost:8080"); 

    // 是否允许请求携带cookie等信息
    cors.setAllowCredentials(true);

    // 设置允许的请求方式
    cors.addAllowedMethod("*");

    // 设置允许的header
    cors.addAllowedHeader("*");

    // 2. 为url添加映射路径
    UrlBasedCorsConfigurationSource corsSource = new UrlBasedCorsConfigurationSource();
    corsSource.registerCorsConfiguration("/**", cors);      // /**表示匹配多级,包括子文件夹, /*表示匹配一级

    // 3. 返回定义好的corsSource
    return new CorsFilter(corsSource);
}
```



- Nginx 解决跨域

```nginx
server {
    listen 80;
    server_name localhost;
    
    #允许跨域请求的域，*代表所有
    add_header 'Access-Control-Allow-Origin' *;
    #允许带上cookie请求
    add_header 'Access-Control-Allow-Credentials' 'true';
    #允许请求的方法，比如 GET/POST/PUT/DELETE
    add_header 'Access-Control-Allow-Methods' *;
    #允许请求的header
    add_header 'Access-Control-Allow-Headers' *;
    
    location / {}
}
```

配置完成后，再次发送跨域请求，成功访问返回200，响应头如下所示

```
Response Headers
    Access-Control-Allow-Credentials: true;
    Access-Control-Allow-Methods; *;
    Access-Control-Allow-Headers: *;
    Access-Control-Allow-Origin: *;
    .....

```



## 2.2 防盗链

当其他站点请求本站点的资源时，即盗链，我们可以修改 Nginx 的配置来进行防盗链

```nginx
#对源站点验证
valid_referers *.imooc.com;
#非法引入会进入下方判断
if ($invalid_referer) {
	return 404;
}
```



## 2.3 Nginx 的模块

主要就是 Nginx 的目录结构，各个目录的内容和作用，这里省略了。



## 2.4 负载均衡的类型

负载均衡分为两种，分别是**传输层负载均衡**和**应用层负载均衡**。由于传输层是第四层应用层在第七次，也称为四层负载均衡和七层负载均衡。

传输层负载均衡即在 TCP 连接上进行负载均衡，常见有 F5 硬件负载均衡；LVS 传输层负载均衡，基于 Linux 内核；HaProxy 负载均衡；Nginx（1.9版本之后支持）

应用层负载均衡即在 HTTP 协议上进行负载均衡，常见有 Nginx，HaProxy，Apache



**应用层：** 这是面向用户的，最靠近用户，为了让用户和计算机交互，在计算机里会有很多软件，比如eclipse，idea，qq，nginx等，这 软件，用户可以通过这些应用软件和计算机交互，交互的过程其实就是接口的调用，应用层为用户提供了交互的接口，以此为用户提供 那么在这一层最常见的协议有：HTTP,HTTPS,FTP,SMTP,POP3等。Nginx在本层，为七层负载均衡。 举例：我要寄一封信给远在天边的老外LiLei，我会打开快递软件下单，这个时候我是 用户 ，快递软件就是 应用服务 ，是建立在计算机 供给用户交互的一种服务或称之为手段。 

**表示层：** 该层提供数据格式编码以及加密功能，确保 请求端 的数据能被 响应端 的应用层识别。 举例：我写中文给LiLei，他看不懂，这个时候我就会使用翻译软件把中文翻译成英文，随后信中涉及到一些比较隐私的信息我会加密一 候翻译软件和加密器就充当了 表示层 的作用，他用于显示用户能够识别的内容。 

**会话层：** 会话可以理解为session，请求发送到接受响应的这个过程之间存在会话，会话层就充当了这一过程的管理者，从创建会话到 后销毁会话。 举例：我每次写信给LiLei都会记录在一个小本本上，寄信时间日期，收信时间日期，这本小本本上存有每次通信记录，这个小本本就相 会话的管理者。又或者说，我们平时在打电话，首先需要拨打电话，这是 建立会话 ，对方接听电话，此时正在通话（ 维持并管理会话 结束后 会话销毁 ，那么这也是一次会话的生命周期。 

**传输层：** 该层建立端到端的连接，他提供了数据传输服务，在传输层通信会涉及到端口号，本层常见的协议为TCP、UDP，LVS就是在 也就是四层负载均衡。 举例：我和LiLei通信过程中会借助快递公司，快递公司会分配快递员取件和寄件，那么这个快递员则充当 传输层 的作用。 

网络层： 网络通信的时候必须要有本机IP和对方的IP，请求端和响应端都会有自己的IP的，IP就相当于你家地址门牌号，在网络上云服 的公网IP，普通计算机也有，只不过是动态IP，运营商每天会分配不同的IP给你的计算机。所以网络层也能称之为IP层，IP是互联网的 能提供IP分配的设备则为路由器或交换机。 举例：对于拥有固定IP的云服务来说，他们都是由腾讯云、阿里云等这样的供应商提供的，他们为云服务器提供固定ip；电信、移动、 商为你的计算机动态分配ip，每天都不同；则这些供应商和运营商都是网络层。同理，快递员由物流公司分配和管理，那么物流公司就 咯。 

**数据链路层：** 这一层会提供计算机MAC地址，通信的时候会携带，为了确保请求投递正确，所以他会验证检测MAC地址，以确保请求 性。 举例：快递员在投递派送的时候，他（或客服）会预先提前打电话给你，确认你家地址对不对、有没有人、货到付款有没有准备好钱等 候快递员（或客服）就充当了 数据链路层 的职责。



**DNS 地域负载均衡**



DNS 会将域名优先解析为地域上更近的服务器 ip 地址，这样就能提高访问速度。

![image-20211111105611715](https://raw.githubusercontent.com/maoturing/PictureBed/master/picGo/image-20211111105611715.png)



## 2.5 Nginx 构建 Tomcat 集群

![image-20211111122909902](https://raw.githubusercontent.com/maoturing/PictureBed/master/picGo/image-20211111122909902.png)



下面的配置，表示 Nginx 会将请求转发给上游服务 upstream，并且会轮询将请求分发给各个Tomcat。Nginx 在 192.168.1.172 上，也就是 localhost

```nginx
#配置上游服务器
upstream tomcats {
    server 192.168.1.173:8080;
    server 192.168.1.174:8080;
    server 192.168.1.175:8080;
}

server {
    listen  80;
    server_name  localhost;
    
    location / {
        proxy_pass http://tomcats;
    }
}
```

然后我们访问`192.168.1.172:80` 时，就可以轮流显示 3 个 Tomcat 的首页，当然地址栏不会有变化，我们可以修改 Tomcat 的首页 index.jsp 来查看这个变化。





上面的配置是轮询的负载均衡策略，我们也可以使用`weight`参数来为不同的服务设置不同的权重.

```nginx
#配置上游服务
upstream tomcats {
    server 192.168.1.173:8080 weight=1;
    server 192.168.1.174:8080 weight=2; 
    server 192.168.1.175:8080 weight=5;
}
```





## 2.6 upstream 参数

 [Nginx upstream 参数详解 - Nginx 官方文档](https://nginx.org/en/docs/stream/ngx_stream_upstream_module.html)



- `max_conns`  限流，限制到指定服务的最大连接数，默认值为 0，表示没有限制。如果 Nginx 分发请求到服务时，发现已经达到了最大连接数，则 Nginx 直接返回给浏览器 502 Bad GateWay。

```nginx
upstream tomcats {
    server 192.168.1.173:8080 max_conns=2;
    server 192.168.1.174:8080 max_conns=2; 
    server 192.168.1.175:8080 max_conns=2;
}
```



- `down`  表示该服务无法访问，nginx 不会把请求转发给 down 掉的服务

```nginx
upstream tomcats {
    # nginx不会把请求转发给这个tomcat服务
    server 192.168.1.173:8080 down;
    
    server 192.168.1.174:8080; 
    server 192.168.1.175:8080;
}
```



- `backup`  表示该服务是备用，只有其他服务都坏掉，才会顶上来提供服务
  我们直接访问 172， Nginx 会把请求均衡的发给 174 和 175 的 Tomcat，如果我们把 174 和175 的 Tomcat 服务停掉，再访问 172，Nginx 就会把请求转发给备用的 173 的 Tomcat 服务了

```nginx
upstream tomcats {
    # 该服务是备用
    server 192.168.1.173:8080 backup;
    
    server 192.168.1.174:8080; 
    server 192.168.1.175:8080;
}
```



- `max_fails`  请求服务的最大失败次数。在`fail_timeout`时间内，当请求某个服务失败达到最大次数，则认为该服务 down 掉了，那么直接将节点标记为不可用，并等待下一个`fail_timeout`周期。默认为1，这里请求失败指的是服务端发生错误或超时

- `fail_timeout`  请求服务失败到达指定次数，被认为服务不可用的时间。默认为 10 秒。

- `slow_start`   慢慢启动，会将权重逐渐提升，商业版才可以使用

  

## 2.7 KeepAlived 提高吞吐量

> 什么是吞吐量？

// 补充



在 Nginx 中开启了 keepalive，经测试，吞吐量提高了一倍。keepalive 在前面已经解释过，访问一次页面其实对服务会发送多次请求，每次都创建新的 TCP 连接浪费资源，建立长连接 KeepAlive。

```nginx
upstream tomcats { 
    server 192.168.1.190:8080; 
    keepalive  32;
} 
server { 
    listen 80; 
    server_name localhost; 
    location / { 
        proxy_pass http://tomcats; 
        proxy_http_version 1.1; 
        proxy_set_header Connection ""; 
    } 
}
```

keepalived ： 设置长连接处理的数量 

proxy_http_version ：设置长连接http版本为1.1 

proxy_set_header ：清除connection header 信息 



## 2.8 负载均衡策略 ip-hash



![image-20211111193347920](https://raw.githubusercontent.com/maoturing/PictureBed/master/picGo/image-20211111193347920.png)

Nginx 负载均衡应该针对 ip 而不是请求，同一个 ip 的所有请求均会分发给同一个 Tomcat，这样 Session 就不会失效了。但是如果用户的动态 ip 发生了变化，那么 Session 就会失效。



Nginx 会对请求的 ip 求 Hash 值，然后对 Tomcat 节点数量求模运算，得到分发 Tomcat 的索引。

```latex
hash(ip) % node_counts = index
```



在 Nginx 中配置 ip-hash 的负载均衡策略

```nginx
upstream tomcats { 
    ip_hash;
    
    server 192.168.1.173:8080; 
    server 192.168.1.174:8080; 
    server 192.168.1.175:8080; 
} 
```

经过测试，同一个 ip 访问 192.168.1.172 总是会访问到同一个 Tomcat 首页，换一个 ip 才会访问到其他 Tomcat，这就是根据 ip-hash 负载均衡的结果。



两个 ip 如果在同一个局域网，即 ip 地址前三位相同，那么会被 Nginx 分发到同一个 Tomcat，从 Nginx 源码可知，Nginx 的 ip-hash 负载均衡的计算规则，只对 ip 地址前三位进行 hash。

```c
// 源码 nginx-1.15.1/src/http/modules/ngx_http_upstream_ip_hash_module.c

iphp->addrlen = 3;
// 循环对ip地址的前三位进行hash运算
for (i = 0; i < (ngx_uint_t) iphp->addrlen; i++) {
    hash = (hash * 113 + iphp->addr[i]) % 6271;
}
```

需要注意，在使用 ip-hash 策略时，如果一台服务挂掉了，不应该在配置中直接删除，而应该将服务标记为 down 状态，因为如果直接删除，那么节点数量 `node_counts`会发生变化，那么一个 ip 分发的 Tomcat 也会发生变化，导致 Session 失效。如果修改为 down 则不会出现该问题，Nginx 会将原本分发给 down 状态节点的请求，发给其他节点。

```nginx
upstream tomcats { 
    ip_hash;
    
    server 192.168.1.173:8080; 
    server 192.168.1.174:8080; 
    
    # 服务挂掉,不能直接删除,否则会影响ip_hash计算
    server 192.168.1.175:8080 down; 
} 
```





## 2.9 一致性 Hash 算法（重点）

> Hash 算法带来的问题

当新增节点和删除节点时，会导致所有的请求重新计算目标节点，这样代价太大。



一致性 Hash 算法，就是将节点均匀的分布在一个环上，将请求按照`hash(ip)`顺时针就近分配给节点。(这里的hash结果会均匀分布在 0-2^32-1 之间)

方便记忆可以理解为学区房，孩子上学都是就近上学，如果建设了新学校，会将附近的学区房划归到新学校。

![image-20211111211041607](https://raw.githubusercontent.com/maoturing/PictureBed/master/picGo/image-20211111211041607.png)



**减少节点**

当减少服务器节点 3 时，会将原先节点 3 的请求（最下面的两个请求），就近分配给节点 4，这样其他请求不会有变化，如下图所示。

![image-20211111211109945](https://raw.githubusercontent.com/maoturing/PictureBed/master/picGo/image-20211111211109945.png)

**新增节点**

当增加服务器节点时，会将原先分配给节点 3 ，且距离新节点更近的请求（最下方的请求），分配给新节点，这样也不会影响其他节点。

![image-20211111211200972](https://raw.githubusercontent.com/maoturing/PictureBed/master/picGo/image-20211111211200972.png)

```nginx
upstream tomcats { 
    # 根据ip地址进行一致性hash
	consistent_hash $remote_addr;
    
    server 192.168.1.173:8080; 
    server 192.168.1.174:8080; 
    server 192.168.1.175:8080; 
} 
```





## 2.10 负载均衡策略 url_hash 与 least_conn

url_hash 与负载均衡策略 ip_hash 类似，后者是对请求者的 ip 进行哈希求模，前者是对请求的 url 进行哈希求模，然后将请求分配给指定的 Tomcat。当然，显而易见，这种策略 Session 无法共享。



![image-20211111214512751](https://raw.githubusercontent.com/maoturing/PictureBed/master/picGo/image-20211111214512751.png)

```nginx
upstream tomcats { 
    hash $request_uri;
    
    server 192.168.1.173:8080; 
    server 192.168.1.174:8080; 
    server 192.168.1.175:8080; 
} 
```

经过测试，访问`192.168.1.172/user/info` 请求到了 173 的 Tomcat，`192.168.1.172/account` 请求到了 174 的Tomcat。



 least_conn 负责均衡策略，会将请求分配给连接数最小的服务，如下图所示，新来的请求一定会分配给 Tomcat3。

![image-20211111215043085](https://raw.githubusercontent.com/maoturing/PictureBed/master/picGo/image-20211111215043085.png)

```nginx
upstream tomcats { 
	least-conn;
    
    server 192.168.1.173:8080; 
    server 192.168.1.174:8080; 
    server 192.168.1.175:8080; 
} 
```



## 2.11 Nginx 控制浏览器缓存



浏览器会缓存请求到的静态资源（css，js，img），Nginx 也会缓存上游服务器发送的静态资源，这样就能节省带宽了。

![image-20211111220448485](https://raw.githubusercontent.com/maoturing/PictureBed/master/picGo/image-20211111220448485.png)

当浏览器请求静态资源，我们可以在 F12 中看到资源的大小，如果是缓存，则会显示**磁盘缓存**或**内存缓存**，这时我们可以强制刷新`ctrl+shift+r`，则所有资源都从服务端获取，当然也可以在浏览器中禁用缓存`disable cache`。



课程中说返回 HTTP 状态码`304`则表示使用了缓存，不知道是怎么回事？而且课程中服务端静态资源修改后，因为资源的`last-modified`改变，普通刷新也会不使用缓存而请求新资源，而在我的开发经历中，好像并不是如此（应该是后端修改不生效吧）。





200  

304    

```nginx
    location /static {
        alias   /home/imooc;

        # 设置资源过期时间为10s
        expires 10s;
    }
```

经过上面修改后，请求返回头中有`Cache-Control: max-age=10` `Expires: Fri, 11 Oct 2019 08:42:10 GMT`，即资源的过期时间为 10 秒。



[200（强缓存）和304（协商缓存）的区别](https://www.cnblogs.com/leftJS/p/11082777.html)





缓存的其他设置方式，不重要。

```nginx
    location /static {
        alias   /home/imooc;

        # 设置资源过期时间为10s
        # expires 10s;
    	# 在22:30过期,max-age会动态变化,大小是当前时间距离过期时间的差值 
    	# expires @22h30m;
    	# 过期时间设置为当前时间减1小时,即不使用缓存,cache-control:no-cache
    	# expires -1h;
    	# 不使用缓存, cache-control:no-cache
    	# expires epoch;
    	# 
    	# expires off;
    	# 将过期时间设置为最大,cache-control:max-age=315360000
    	# expires max;
    }
```





## 2.12 Nginx 缓存配置

1. Nginx 缓存上游服务器的静态资源，配置缓存目录，缓存大小，定期清理时间等。

   共享内存是什么？

```nginx
# proxy_cache_path 设置缓存目录
# keys_zone 设置共享内存名称和大小
# max_size 设置缓存大小
# inactive 超过此时间则被清理
# use_temp_path 临时目录，使用后会影响nginx性能
http {
	proxy_cache_path /usr/local/nginx/upstream_cache keys_zone=mycache:5m max_size=1g inactive=1m use_temp_path=off;
}
```

2. 配置开启 Nginx 缓存，设置过期时间

```nginx
location / {
	proxy_pass http://tomcats;
	# 启用缓存，和keys_zone一致
	proxy_cache mycache;
	# 针对200和304状态码缓存时间为8小时
	proxy_cache_valid 200 304 8h;
}
```

3. 访问`192.168.1.172`，可以在 Nginx 机器目录 `/usr/local/nginx/upstream_cache` 看到生成的缓存文件



## 2.13 配置 SSL 证书提供 HTTPS

> 什么是 HTTPS，SSL 协议原理

详细见《码农翻身》 p205 笔记，已经完全搞清楚了 HTTPS

[SSL/TLS协议运行机制的概述 - 阮一峰](https://www.ruanyifeng.com/blog/2014/02/ssl_tls.html)





1. 在腾讯云或阿里云申请证书，会获得一个`.crt` 证书文件和`.key`秘钥文件
2. 为 Nginx 安装 SSL 模块，编译安装 Nginx，详细见文档2-36
3. 把ssl证书 *.crt 和 私钥 *.key 拷贝到 /usr/local/nginx/conf 目录中
4. 为 Nginx 配置 HTTPS，监听 443 端口。重新加载配置文件

```nginx
server {
	listen 443;
	server_name www.imoocdsp.com;
    # 开启ssl
    ssl on;
    # 配置ssl证书
    ssl_certificate 1_www.imoocdsp.com_bundle.crt;
    # 配置证书秘钥
    ssl_certificate_key 2_www.imoocdsp.com.key;
    # ssl会话cache
    ssl_session_cache shared:SSL:1m;
    # ssl会话超时时间
    ssl_session_timeout 5m;
    # 配置加密套件，写法遵循 openssl 标准
    ssl_protocols TLSv1 TLSv1.1 TLSv1.2;
    ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE;
    ssl_prefer_server_ciphers on;
    
    location / {
    	proxy_pass http://tomcats/;
        index index.html index.htm;
    }
}
```



[HTTPS 升级指南 - 阮一峰](http://www.ruanyifeng.com/blog/2016/08/migrate-from-http-to-https.html)



## 2.14 动静分离



**CDN 动静分离**

前面我们说过，DNS 解析会把请求，分配给地域上最近的服务器。而 CDN 主要是针对 `vue.js`，`jquery.js`等常用的静态资源文件，我们不会引入使用我们服务端本地的静态资源，而是会使用第三方的，这样就能从最近的服务器中拉取资源，既能节省访问时间，又能节省服务器带宽。

```js
<script src="https://cdn.jsdelivr.net/npm/vue@2.5.16/dist/vue.js"></script>
```



**Nginx 动静分离**

![image-20211112123432855](https://raw.githubusercontent.com/maoturing/PictureBed/master/picGo/image-20211112123432855.png)



> 动静分离带来的问题

- 跨域     解决办法： SpringBoot，Nginx 配置，jsonp
- 分布式会话     解决办法：分布式缓存中间件redis











## 2.15 部署 Nginx 到云端

![image-20211112110357419](https://raw.githubusercontent.com/maoturing/PictureBed/master/picGo/image-20211112110357419.png)



![image-20211112110413082](https://raw.githubusercontent.com/maoturing/PictureBed/master/picGo/image-20211112110413082.png)



1. 反向代理，后端项目打包上传到 172.17.41.6 的 Tomcat 中，然后浏览器请求`http://api.z.mukewang.com`时，Nginx 会将请求反向代理，发给`172.17.41.6:8088`，Tomcat 接收请求并进行响应。

   注意需要将`app.js`中对后端发送的请求，url 需要从`http://api.z.mukewang.com:8088/foodie-dev-api`修改为`http://api.z.mukewang.com/foodie-dev-api`

```nginx
// 配置上游的tomcat服务
upstream api.z.mukewang.com { 
    server 172.17.41.6:8088; 
} 
server {
    listen 80;
    server_name api.z.mukewang.com;
    
    // 将监听到的请求反向代理,发送给172.17.41.6:8088
    location ~ {
        proxy_pass http://api.z.mukewang.com;
    }
}
```



2. 配置静态资源，首先将前端代码上传到 Nginx 机器的`/home/website/`目录，然后浏览器请求`http://shop.z.mukewang.com/xxx`时会去该目录下查找静态资源。

   注意需要将`app.js`中对其他模块静态资源的请求，url 需要从`http://shop.z.mukewang.com:8080/foodie-shop`修改为`http://shop.z.mukewang.com`

```nginx
server {
    listen 80;
    server_name shop.z.mukewang.com;
    
    // 请求的静态资源,去下面的目录查找
    location / {
        root /home/website/foodie-shop;
        index index.html;
    }
}
```



// 补充









# 3. 高可用集群 Keepalived

上一章我们使用 Nginx 配置了反向代理，但是存在单点问题，如果唯一的 Nginx 节点机器宕机后，整个系统就不可用了。而本章的高可用集群就是为了解决该问题。

![image-20211112154126413](https://raw.githubusercontent.com/maoturing/PictureBed/master/picGo/image-20211112154126413.png)



**KeepAlived 概念**

- 解决单点故障，不仅可以配合 Nginx，也可以配合 Redis 使用
- 可以实现高可用，KeepAlived 会检测 Nginx 状态，若主节点宕机，则会切换到副节点
- 基于 VRRP 协议



**虚拟路由冗余协议 VRRP** 

- Virtual Router Redundancy Protocol
- 解决内网单机故障的路由协议
- 构建有过个路由器 MASTER BACKUP
- 虚拟 IP - VIP （Virtual IP Address）



## 3.1 KeepAlived 双机主备原理

![image-20211217002425315](https://gitee.com/tracccer/picture-bed/raw/master/img/image-20211217002425315.png)

用户访问网站时需要访问虚拟 ip，当前虚拟 ip 与 Nginx 主节点绑定，当 Nginx 主节点宕机，则虚拟 ip 与 Nginx 备用节点绑定。





## 3.2 KeepAlived 安装



1. 下载 [Keepalived for Linux](https://www.keepalived.org/download.html)
2. 上传到 Linux 并解压
3. 配置 KeepAlived，执行`./configure --prefix=/usr/local/keepalived --sysconf=/etc`
4. 安装 KeepAlived `make && make install`
5. KeepAlived 安装目录`/usr/local/keepalived`，配置文件在 `/etc/keepalived/keepalived.conf`
6. 启动 KeepAlived  `./sbin/keepalived`

## 3.3 KeepAlived 配置文件

打开 `/etc/keepalived/keepalived.conf`

```nginx
global_defs { 
	# 路由id：当前安装keepalived的节点主机标识符，保证全局唯一 
    router_id keep_171 
}
vrrp_instance VI_1 { 
    # 表示状态是MASTER主机还是备用机BACKUP 
    state MASTER 
    # 该实例绑定的网卡 
    interface ens33 
    # 保证主备节点一致即可 
    virtual_router_id 51 
    # 权重，master权重一般高于backup，如果有多个，那就是选举，谁的权重高，谁就当选 
    priority 100 
    # 主备之间同步检查时间间隔，单位秒 
    advert_int 2 
    # 认证权限密码，防止非法节点进入 
    authentication { 
        auth_type PASS 
        auth_pass 1111 
    }
    # 虚拟出来的ip，可以有多个（vip） 
    virtual_ipaddress { 
        192.168.1.161 
    } 
}
```

修改保存配置文件后，启动 KeepAlived  `./sbin/keepalived`，然后查看本机 IP `ip addr`，可以看到有 ens 网卡下有两个 ip 地址，上面的是本机的 IP 地址，另一个就是 KeepAlived 配置的虚拟 ip。

![image-20211217005743359](https://gitee.com/tracccer/picture-bed/raw/master/img/image-20211217005743359.png)



// 补充











# 4.  LVS 



// 补充











## 参考文档



1. [尚硅谷Nginx教程由浅入深](https://www.bilibili.com/video/BV1zJ411w7SV?p=17)  注重实战，讲的并没有课程详细

2. [跨域资源共享 CORS 详解 - 阮一峰](http://www.ruanyifeng.com/blog/2016/04/cors.html)

3. [200（强缓存）和304（协商缓存）的区别](https://www.cnblogs.com/leftJS/p/11082777.html)

   





# 学习记录

2021年11月10日21:02:31		第6周 2-5

2021年11月12日01:33:05        第6周 2-32

2021年11月12日23:56:51        第6周 2-38    效率太低了今天，明天加油吧

